{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d178fe1f-5cf0-4778-8801-fa2131883142",
   "metadata": {},
   "source": [
    "### chaptGPT specs   \n",
    "\n",
    "A decoder-only transformer in pytorch to predict 'next output' at each time step. \n",
    "\n",
    "Each time step t is represented by a vector of n=4 tokens from the Descript DAC encoder. \n",
    "The length of the sequence (context window) is Ti=86 for inference, and Tt=8*Ti for training. That is, the context window for training is 8 times the length of the context window for inference. \n",
    "The attention is \"causal\", looking only back in time, and the maximum look-back time for the attention blocks is Ti (even when the sequence is longer during training). That is, the masking matrix is *banded* - triangular to be causal, and limited in lookback which results in a diagonal band). This prevents much of the training on shortened context that happens when tokens are near the beginning of traning examples. \n",
    "\n",
    "The size of the vocabulary (the number of descrete values in each codebook) for each of the n tokens is V=1024. \n",
    "\n",
    "The dataloader will as is usual, supply batches in triplets  (input, target, conditioning info) where the size of each input and output is Tt*n (the sequence length times the number of tokens at each time step). The tokens are indexes for the vocabulary in the range of (0, V-1). The targets are shifted relative to the input sequence by 1 as is typical for networks the learn to predict the output for the next time step. \n",
    "\n",
    "The first layer in the architecture will be a learnable \"multiembedding\" layer that embeds each of the 4 tokens at each time step as an m-dimensional vector. The n m-dimensional vectors are concatenated to provide the n*m dimensional input embeddings for the transformer blocks at each time step. \n",
    "\n",
    "A positional code is is added to the K and Q matricies in each Transformer block using Rotary Position Embedding (RoPE).\n",
    "\n",
    "We use a stack of b transformer blocks that are standard (using layer norms, a relu for activation, and a forward expansion factor of 4 form the linear layer). Each transformer block consumes and produces a context window length sequence of m*n dimensional vectors. \n",
    "\n",
    "After the last transformer block, there is a linear layer that maps the m*n dimensional vectors to the output size which is V*n (the vocabulary size time the number of tokens stacked at each time step). These are the logits that will be fed to the softmax functions (one for each of the n to kens) that provide the probability distribtion across the vocabulary set. We use the criterion nn.CrossEntropyLoss() for computing the loss using the targets provided by the dataloader, and Adam for the optimizer.\n",
    "\n",
    "Again, at inference time, the fixed-length context window is shorter than the training sequence window length, and equal to the maximum look-back time of the attention blocks. The inference process takes the output produced at each time step (a stack of n tokens), and shift them in to a sliding window that is used for input for the next time step. The length of the sequences generated during inference is arbitrary and should be settable with a parameter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8db8df-da27-4eb1-91c5-1d4945ff4161",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce614c-47d9-4e16-bee8-3fbcc556b08a",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad58d43c-b453-496f-8a43-f0a1722b8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile = 'params_mini.yaml' # 'params.yaml' #\n",
    "DEVICE='cuda'\n",
    "start_epoch=0 # to start from a previous training checkpoint, otherwise must be 0\n",
    "verboselevel=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9760e14-8c2f-4a14-be94-f1ef300296ce",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d67b59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# and for creating a custom dataset and loader:\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "from utils.utils import generate_mask, save_model, load_model, writeDACFile, interpolate_vectors\n",
    "from DACTransformer.RopeCondDACTransformer import RopeCondDACTransformer\n",
    "\n",
    "from dataloader.dataset import CustomDACDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76dcc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b85ef",
   "metadata": {},
   "source": [
    "### <font color='blue'> Derived parameters </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "638ee684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_size is 512\n",
      "using TransformerClass = RopeCondDACTransformer\n",
      "basefname = out.e512.l4.h8\n",
      "outdir = runs/mini_test_01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/mini_test_01/params.yaml'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data dir\n",
    "\n",
    "# Load YAML file\n",
    "with open(paramfile, 'r') as file:\n",
    "    params = yaml.safe_load(file)\n",
    "\n",
    "data_dir = params['data_dir']\n",
    "data_frames =  params['data_frames']\n",
    "validator_data_dir = params['validator_data_dir']\n",
    "validator_data_frames = params['validator_data_frames']\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CustomDACDataset(data_dir=data_dir, metadata_excel=data_frames, transforms=None)\n",
    "\n",
    "# ---------     for the transformer  --------------#\n",
    "vocab_size = params['vocab_size']\n",
    "num_tokens = params['num_tokens']\n",
    "\n",
    "cond_classes = dataset.get_num_classes() # 0\n",
    "cond_params = params['cond_params']\n",
    "cond_size = cond_classes + cond_params # num_classes + num params - not a FREE parameter!\n",
    "\n",
    "#embed_size = params['tblock_input_size'] -cond_size # 240 #32  # embed_size +cond_size must be divisible by num_heads and by num tokens\n",
    "embed_size = params['model_size']  # embed_size  must be divisible by num_heads and by num tokens\n",
    "print(f'embed_size is {embed_size}')\n",
    "\n",
    "Ti = params['Ti']\n",
    "Tt = params['Tt']\n",
    "batch_size = params['batch_size']\n",
    "\n",
    "sequence_length = Tt  # For training\n",
    "\n",
    "num_layers = params['num_layers']\n",
    "num_heads = params['num_heads']\n",
    "forward_expansion = params['forward_expansion']\n",
    "dropout_rate = params['dropout_rate']\n",
    "learning_rate = params['learning_rate']\n",
    "num_epochs=params['num_epochs']\n",
    "\n",
    "experiment_name=params['experiment'] \n",
    "outdir = 'runs' + '/' + experiment_name\n",
    "basefname= 'out' + '.e' + str(embed_size) + '.l' + str(num_layers) + '.h' + str(num_heads) \n",
    "\n",
    "ErrorLogRate = params['ErrorLogRate'] #10\n",
    "checkpoint_interval = params['checkpoint_interval']\n",
    "\n",
    "\n",
    "\n",
    "TransformerClass =  globals().get(params['TransformerClass'])  \n",
    "\n",
    "print(f\"using TransformerClass = {params['TransformerClass']}\") \n",
    "print(f'basefname = {basefname}')\n",
    "print(f'outdir = {outdir}')\n",
    "\n",
    "###########################################################################\n",
    "# Ensure the destination directory exists\n",
    "#destination_dir = os.path.dirname(outdir + '/' + paramfile)\n",
    "#if not os.path.exists(destination_dir):\n",
    "#    os.makedirs(destination_dir)\n",
    "    \n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "shutil.copy(paramfile, outdir + '/params.yaml')  # copy whatever paramfile was used to outdir and name it params.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf3928",
   "metadata": {},
   "source": [
    "### <font color='blue'> Set up cuda. \n",
    "Without it, training runs about 10 times slower  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ff0adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memeory on cuda 0 is  4.294639616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEVICE == 'cuda' :\n",
    "    torch.cuda.device_count()\n",
    "    torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "\n",
    "    device = torch.device(DEVICE) # if the docker was started with --gpus all, then can choose here with cuda:0 (or cpu)\n",
    "    torch.cuda.device_count()\n",
    "    print(f'memeory on cuda 0 is  {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "else :\n",
    "    device=DEVICE\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee7020c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Load data \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c684557b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "Inputs shape: torch.Size([4, 295, 4])\n",
      "Targets shape: torch.Size([4, 295, 4])\n",
      "cvect shape: torch.Size([4, 5])\n",
      "cevect is tensor([[0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 1.],\n",
      "        [0., 1., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Validator data set\n",
    "if validator_data_dir != None :\n",
    "    validator_dataset=CustomDACDataset(data_dir=validator_data_dir, metadata_excel=validator_data_frames)\n",
    "    validator_dataloader= DataLoader(validator_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# Test data dir\n",
    "for batch_idx, (inputs, targets, cvect) in enumerate(dataloader):\n",
    "    #pass\n",
    "    # Your training code here\n",
    "    # inputs: batch of input data of shape [batch_size, N, T-1]\n",
    "    # targets: corresponding batch of target data of shape [batch_size, N, T-1]\n",
    "    \n",
    "    if (batch_idx == 0) : \n",
    "        print(f\"Batch {batch_idx + 1}\")\n",
    "        print(f\"Inputs shape: {inputs.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "        print(f\"cvect shape: {cvect.shape}\")\n",
    "        print(f'cevect is {cvect}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0eb6c",
   "metadata": {},
   "source": [
    "### <font color='blue'> Make the mask \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c9b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask.shape is torch.Size([295, 295])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [-inf, -inf, -inf,  ..., 0., -inf, -inf],\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., -inf],\n",
       "        [-inf, -inf, -inf,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = generate_mask(Tt, Ti).to(device)\n",
    "print(f'Mask.shape is {mask.shape}')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11c4b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model with embed_size=512, cond_size=5\n",
      " ------------- embed_dim (512) must be divisible by num_heads (8)\n",
      "Setting up MultiEmbedding with vocab_size= 1024, embed_size= 512, num_codebooks= 4\n",
      "Setting up RotaryPositionalEmbedding with embed_size= 512, max_len= 295\n",
      "Total number of parameters: 16295936\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model, put it on the device\n",
    "#model = TransformerDecoder(embed_size, num_layers, num_heads, forward_expansion, dropout_rate, Tt, num_tokens, vocab_size).to(device)\n",
    "print(f'Creating model with embed_size={embed_size}, cond_size={cond_size}')\n",
    "\n",
    "if start_epoch == 0 : \n",
    "    model = TransformerClass(embed_size, num_layers, num_heads, forward_expansion, dropout_rate, Tt, cond_classes, num_tokens, vocab_size, cond_size, verboselevel).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "else:\n",
    "    checkpoint_path = outdir+\"/\"+basefname+\"_chkpt_\"+str(start_epoch).zfill(4) +\".pth\"\n",
    "    print(f'in train, start_epoch = {start_epoch} and checkpoint_path = {checkpoint_path}')\n",
    "    assert os.path.exists(checkpoint_path), f\"{checkpoint_path} does not exist.\"\n",
    "    if start_epoch != 0 and checkpoint_path and os.path.exists(checkpoint_path):\n",
    "        print(f\"Loading and creating model from {checkpoint_path}\")       \n",
    "        # Restore model weights\n",
    "        model, optimizer, _, vocab_size, num_tokens, cond_size = load_model(checkpoint_path,  TransformerClass, device)\n",
    "        #best_metric = checkpoint['best_metric']  # If you're tracking performance      \n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "   \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {num_params}')\n",
    "\n",
    "# Initialize SummaryWriter for tensorboard \n",
    "writer = SummaryWriter(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85526818-66e9-4bf0-9a94-0334ecd39d61",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; height: 20px; background-color: black;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf2f038",
   "metadata": {},
   "source": [
    "# <font color='blue'> Train !! \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb439d-6d8f-4b1c-a4fd-6acac2a07db6",
   "metadata": {},
   "source": [
    "### loss is average CE across all output tokens\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N} \\sum_{n=1}^{N} \\text{CE}(x_n, y_n)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19920362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2  (with max 500), loss: 6.71724271774292\n",
      "Validation Loss: 6.173355579376221\n",
      "train time for 2 epochs, was 0.5889384746551514\n",
      "\n",
      "EPOCH 4  (with max 500), loss: 7.088653564453125\n",
      "Validation Loss: 6.127959728240967\n",
      "train time for 4 epochs, was 0.9723138809204102\n",
      "\n",
      "EPOCH 5 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0005.pth\n",
      "\n",
      "EPOCH 6  (with max 500), loss: 6.040456295013428\n",
      "Validation Loss: 5.6185736656188965\n",
      "train time for 6 epochs, was 3.3065085411071777\n",
      "\n",
      "EPOCH 8  (with max 500), loss: 5.439266681671143\n",
      "Validation Loss: 4.916060447692871\n",
      "train time for 8 epochs, was 3.6780471801757812\n",
      "\n",
      "EPOCH 10  (with max 500), loss: 4.944605350494385\n",
      "Validation Loss: 4.470635890960693\n",
      "train time for 10 epochs, was 4.050341844558716\n",
      "\n",
      "EPOCH 10 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0010.pth\n",
      "\n",
      "EPOCH 12  (with max 500), loss: 4.436800003051758\n",
      "Validation Loss: 3.9613847732543945\n",
      "train time for 12 epochs, was 5.576999187469482\n",
      "\n",
      "EPOCH 14  (with max 500), loss: 4.015646934509277\n",
      "Validation Loss: 3.292647123336792\n",
      "train time for 14 epochs, was 5.954340219497681\n",
      "\n",
      "EPOCH 15 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0015.pth\n",
      "\n",
      "EPOCH 16  (with max 500), loss: 3.333167791366577\n",
      "Validation Loss: 2.6451220512390137\n",
      "train time for 16 epochs, was 7.50317120552063\n",
      "\n",
      "EPOCH 18  (with max 500), loss: 2.6890017986297607\n",
      "Validation Loss: 1.9917850494384766\n",
      "train time for 18 epochs, was 7.884997606277466\n",
      "\n",
      "EPOCH 20  (with max 500), loss: 2.083585739135742\n",
      "Validation Loss: 1.3818352222442627\n",
      "train time for 20 epochs, was 8.26387333869934\n",
      "\n",
      "EPOCH 20 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0020.pth\n",
      "\n",
      "EPOCH 22  (with max 500), loss: 1.5848510265350342\n",
      "Validation Loss: 0.9305197596549988\n",
      "train time for 22 epochs, was 9.842769622802734\n",
      "\n",
      "EPOCH 24  (with max 500), loss: 1.125065803527832\n",
      "Validation Loss: 0.5748852491378784\n",
      "train time for 24 epochs, was 10.24915099143982\n",
      "\n",
      "EPOCH 25 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0025.pth\n",
      "\n",
      "EPOCH 26  (with max 500), loss: 0.7012468576431274\n",
      "Validation Loss: 0.2900884449481964\n",
      "train time for 26 epochs, was 11.975090503692627\n",
      "\n",
      "EPOCH 28  (with max 500), loss: 0.4597419798374176\n",
      "Validation Loss: 0.14250843226909637\n",
      "train time for 28 epochs, was 12.363816499710083\n",
      "\n",
      "EPOCH 30  (with max 500), loss: 0.2817366123199463\n",
      "Validation Loss: 0.07175375521183014\n",
      "train time for 30 epochs, was 12.752431154251099\n",
      "\n",
      "EPOCH 30 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0030.pth\n",
      "\n",
      "EPOCH 32  (with max 500), loss: 0.18455150723457336\n",
      "Validation Loss: 0.035660311579704285\n",
      "train time for 32 epochs, was 14.498847961425781\n",
      "\n",
      "EPOCH 34  (with max 500), loss: 0.11727862805128098\n",
      "Validation Loss: 0.02075105346739292\n",
      "train time for 34 epochs, was 14.883814811706543\n",
      "\n",
      "EPOCH 35 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0035.pth\n",
      "\n",
      "EPOCH 36  (with max 500), loss: 0.08439648151397705\n",
      "Validation Loss: 0.01166474912315607\n",
      "train time for 36 epochs, was 16.473501682281494\n",
      "\n",
      "EPOCH 38  (with max 500), loss: 0.05088406801223755\n",
      "Validation Loss: 0.006737146060913801\n",
      "train time for 38 epochs, was 16.85273051261902\n",
      "\n",
      "EPOCH 40  (with max 500), loss: 0.04012181982398033\n",
      "Validation Loss: 0.004443241748958826\n",
      "train time for 40 epochs, was 17.248915195465088\n",
      "\n",
      "EPOCH 40 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0040.pth\n",
      "\n",
      "EPOCH 42  (with max 500), loss: 0.03247465193271637\n",
      "Validation Loss: 0.0032418991904705763\n",
      "train time for 42 epochs, was 19.375654458999634\n",
      "\n",
      "EPOCH 44  (with max 500), loss: 0.023907633498311043\n",
      "Validation Loss: 0.00209145643748343\n",
      "train time for 44 epochs, was 19.760395526885986\n",
      "\n",
      "EPOCH 45 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0045.pth\n",
      "\n",
      "EPOCH 46  (with max 500), loss: 0.02261652611196041\n",
      "Validation Loss: 0.0013906351523473859\n",
      "train time for 46 epochs, was 21.778697967529297\n",
      "\n",
      "EPOCH 48  (with max 500), loss: 0.017273787409067154\n",
      "Validation Loss: 0.0009057815768755972\n",
      "train time for 48 epochs, was 22.16674280166626\n",
      "\n",
      "EPOCH 50  (with max 500), loss: 0.01284029521048069\n",
      "Validation Loss: 0.00070392363704741\n",
      "train time for 50 epochs, was 22.550312757492065\n",
      "\n",
      "EPOCH 50 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0050.pth\n",
      "\n",
      "EPOCH 52  (with max 500), loss: 0.013505687937140465\n",
      "Validation Loss: 0.0005439591477625072\n",
      "train time for 52 epochs, was 24.184545516967773\n",
      "\n",
      "EPOCH 54  (with max 500), loss: 0.010837615467607975\n",
      "Validation Loss: 0.0004197738307993859\n",
      "train time for 54 epochs, was 24.572890758514404\n",
      "\n",
      "EPOCH 55 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0055.pth\n",
      "\n",
      "EPOCH 56  (with max 500), loss: 0.007882561534643173\n",
      "Validation Loss: 0.00034763338044285774\n",
      "train time for 56 epochs, was 26.160735845565796\n",
      "\n",
      "EPOCH 58  (with max 500), loss: 0.007854941301047802\n",
      "Validation Loss: 0.00028721720445901155\n",
      "train time for 58 epochs, was 26.55320954322815\n",
      "\n",
      "EPOCH 60  (with max 500), loss: 0.006640264764428139\n",
      "Validation Loss: 0.00025803528842516243\n",
      "train time for 60 epochs, was 26.944193124771118\n",
      "\n",
      "EPOCH 60 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0060.pth\n",
      "\n",
      "EPOCH 62  (with max 500), loss: 0.005462330300360918\n",
      "Validation Loss: 0.00018750391609501094\n",
      "train time for 62 epochs, was 28.643810987472534\n",
      "\n",
      "EPOCH 64  (with max 500), loss: 0.005754995159804821\n",
      "Validation Loss: 0.0001633280626265332\n",
      "train time for 64 epochs, was 29.03644061088562\n",
      "\n",
      "EPOCH 65 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0065.pth\n",
      "\n",
      "EPOCH 66  (with max 500), loss: 0.005072053987532854\n",
      "Validation Loss: 0.00014387679402716458\n",
      "train time for 66 epochs, was 30.628925800323486\n",
      "\n",
      "EPOCH 68  (with max 500), loss: 0.004169114865362644\n",
      "Validation Loss: 0.00012852784129790962\n",
      "train time for 68 epochs, was 31.02124810218811\n",
      "\n",
      "EPOCH 70  (with max 500), loss: 0.004297925159335136\n",
      "Validation Loss: 0.00011113581422250718\n",
      "train time for 70 epochs, was 31.41132116317749\n",
      "\n",
      "EPOCH 70 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0070.pth\n",
      "\n",
      "EPOCH 72  (with max 500), loss: 0.00341486232355237\n",
      "Validation Loss: 9.964344644686207e-05\n",
      "train time for 72 epochs, was 33.11620354652405\n",
      "\n",
      "EPOCH 74  (with max 500), loss: 0.0030195608269423246\n",
      "Validation Loss: 9.321224206360057e-05\n",
      "train time for 74 epochs, was 33.51337194442749\n",
      "\n",
      "EPOCH 75 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0075.pth\n",
      "\n",
      "EPOCH 76  (with max 500), loss: 0.003296314040198922\n",
      "Validation Loss: 8.638840517960489e-05\n",
      "train time for 76 epochs, was 35.10267972946167\n",
      "\n",
      "EPOCH 78  (with max 500), loss: 0.003665067022666335\n",
      "Validation Loss: 8.030854223761708e-05\n",
      "train time for 78 epochs, was 35.48030495643616\n",
      "\n",
      "EPOCH 80  (with max 500), loss: 0.0024774197954684496\n",
      "Validation Loss: 7.394654676318169e-05\n",
      "train time for 80 epochs, was 35.86386585235596\n",
      "\n",
      "EPOCH 80 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0080.pth\n",
      "\n",
      "EPOCH 82  (with max 500), loss: 0.0024561139289289713\n",
      "Validation Loss: 6.788477912778035e-05\n",
      "train time for 82 epochs, was 37.50533843040466\n",
      "\n",
      "EPOCH 84  (with max 500), loss: 0.002320429775863886\n",
      "Validation Loss: 6.255974585656077e-05\n",
      "train time for 84 epochs, was 37.88552522659302\n",
      "\n",
      "EPOCH 85 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0085.pth\n",
      "\n",
      "EPOCH 86  (with max 500), loss: 0.0024677393957972527\n",
      "Validation Loss: 5.5890734074637294e-05\n",
      "train time for 86 epochs, was 39.512882471084595\n",
      "\n",
      "EPOCH 88  (with max 500), loss: 0.0019921937491744757\n",
      "Validation Loss: 5.165695620235056e-05\n",
      "train time for 88 epochs, was 39.89848327636719\n",
      "\n",
      "EPOCH 90  (with max 500), loss: 0.0019628058653324842\n",
      "Validation Loss: 4.938611527904868e-05\n",
      "train time for 90 epochs, was 40.28490138053894\n",
      "\n",
      "EPOCH 90 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0090.pth\n",
      "\n",
      "EPOCH 92  (with max 500), loss: 0.0017551482887938619\n",
      "Validation Loss: 4.6726458094781265e-05\n",
      "train time for 92 epochs, was 41.9278461933136\n",
      "\n",
      "EPOCH 94  (with max 500), loss: 0.0018507359782233834\n",
      "Validation Loss: 4.467152029974386e-05\n",
      "train time for 94 epochs, was 42.32129764556885\n",
      "\n",
      "EPOCH 95 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0095.pth\n",
      "\n",
      "EPOCH 96  (with max 500), loss: 0.0014948199968785048\n",
      "Validation Loss: 4.205567165627144e-05\n",
      "train time for 96 epochs, was 43.94238233566284\n",
      "\n",
      "EPOCH 98  (with max 500), loss: 0.0016907112440094352\n",
      "Validation Loss: 3.958816159865819e-05\n",
      "train time for 98 epochs, was 44.33754563331604\n",
      "\n",
      "EPOCH 100  (with max 500), loss: 0.00187413371168077\n",
      "Validation Loss: 3.667767668957822e-05\n",
      "train time for 100 epochs, was 44.73738479614258\n",
      "\n",
      "EPOCH 100 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0100.pth\n",
      "\n",
      "EPOCH 102  (with max 500), loss: 0.0017894045449793339\n",
      "Validation Loss: 3.4460499591659755e-05\n",
      "train time for 102 epochs, was 46.388888120651245\n",
      "\n",
      "EPOCH 104  (with max 500), loss: 0.0015729707665741444\n",
      "Validation Loss: 3.238511271774769e-05\n",
      "train time for 104 epochs, was 46.783203125\n",
      "\n",
      "EPOCH 105 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0105.pth\n",
      "\n",
      "EPOCH 106  (with max 500), loss: 0.0018052379600703716\n",
      "Validation Loss: 3.101709080510773e-05\n",
      "train time for 106 epochs, was 48.41645812988281\n",
      "\n",
      "EPOCH 108  (with max 500), loss: 0.0015817383537068963\n",
      "Validation Loss: 3.0359660740941763e-05\n",
      "train time for 108 epochs, was 48.81247687339783\n",
      "\n",
      "EPOCH 110  (with max 500), loss: 0.0017399779753759503\n",
      "Validation Loss: 3.015933179995045e-05\n",
      "train time for 110 epochs, was 49.207274198532104\n",
      "\n",
      "EPOCH 110 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0110.pth\n",
      "\n",
      "EPOCH 112  (with max 500), loss: 0.0012298999354243279\n",
      "Validation Loss: 3.063589247176424e-05\n",
      "train time for 112 epochs, was 50.84006357192993\n",
      "\n",
      "EPOCH 114  (with max 500), loss: 0.0012399560073390603\n",
      "Validation Loss: 3.074064079555683e-05\n",
      "train time for 114 epochs, was 51.22807812690735\n",
      "\n",
      "EPOCH 115 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0115.pth\n",
      "\n",
      "EPOCH 116  (with max 500), loss: 0.001570894499309361\n",
      "Validation Loss: 3.0055680326768197e-05\n",
      "train time for 116 epochs, was 52.86921048164368\n",
      "\n",
      "EPOCH 118  (with max 500), loss: 0.0018550313543528318\n",
      "Validation Loss: 2.8709881007671356e-05\n",
      "train time for 118 epochs, was 53.26599144935608\n",
      "\n",
      "EPOCH 120  (with max 500), loss: 0.0011572801740840077\n",
      "Validation Loss: 2.6768391762743704e-05\n",
      "train time for 120 epochs, was 53.663323163986206\n",
      "\n",
      "EPOCH 120 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0120.pth\n",
      "\n",
      "EPOCH 122  (with max 500), loss: 0.001321849413216114\n",
      "Validation Loss: 2.5676026780274697e-05\n",
      "train time for 122 epochs, was 55.33386826515198\n",
      "\n",
      "EPOCH 124  (with max 500), loss: 0.0015921661397442222\n",
      "Validation Loss: 2.501965172996279e-05\n",
      "train time for 124 epochs, was 55.73180675506592\n",
      "\n",
      "EPOCH 125 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0125.pth\n",
      "\n",
      "EPOCH 126  (with max 500), loss: 0.0010391504038125277\n",
      "Validation Loss: 2.4683047740836628e-05\n",
      "train time for 126 epochs, was 57.42757749557495\n",
      "\n",
      "EPOCH 128  (with max 500), loss: 0.0012279185466468334\n",
      "Validation Loss: 2.410076922387816e-05\n",
      "train time for 128 epochs, was 57.830352783203125\n",
      "\n",
      "EPOCH 130  (with max 500), loss: 0.0012975299032405019\n",
      "Validation Loss: 2.328263144590892e-05\n",
      "train time for 130 epochs, was 58.22735953330994\n",
      "\n",
      "EPOCH 130 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0130.pth\n",
      "\n",
      "EPOCH 132  (with max 500), loss: 0.00107076286803931\n",
      "Validation Loss: 2.182729986088816e-05\n",
      "train time for 132 epochs, was 59.924477338790894\n",
      "\n",
      "EPOCH 134  (with max 500), loss: 0.0011573644587770104\n",
      "Validation Loss: 2.194548687839415e-05\n",
      "train time for 134 epochs, was 60.32286596298218\n",
      "\n",
      "EPOCH 135 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0135.pth\n",
      "\n",
      "EPOCH 136  (with max 500), loss: 0.0010221259435638785\n",
      "Validation Loss: 3.018001007148996e-05\n",
      "train time for 136 epochs, was 62.02372431755066\n",
      "\n",
      "EPOCH 138  (with max 500), loss: 0.001150842639617622\n",
      "Validation Loss: 1.9907140085706487e-05\n",
      "train time for 138 epochs, was 62.432472944259644\n",
      "\n",
      "EPOCH 140  (with max 500), loss: 0.0008304255898110569\n",
      "Validation Loss: 1.9329701899550855e-05\n",
      "train time for 140 epochs, was 62.8350305557251\n",
      "\n",
      "EPOCH 140 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0140.pth\n",
      "\n",
      "EPOCH 142  (with max 500), loss: 0.0008820125367492437\n",
      "Validation Loss: 1.9045432054554112e-05\n",
      "train time for 142 epochs, was 64.58725070953369\n",
      "\n",
      "EPOCH 144  (with max 500), loss: 0.0008572837105020881\n",
      "Validation Loss: 1.87939585885033e-05\n",
      "train time for 144 epochs, was 64.98865509033203\n",
      "\n",
      "EPOCH 145 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0145.pth\n",
      "\n",
      "EPOCH 146  (with max 500), loss: 0.000933711533434689\n",
      "Validation Loss: 1.7880151062854566e-05\n",
      "train time for 146 epochs, was 66.77862095832825\n",
      "\n",
      "EPOCH 148  (with max 500), loss: 0.0009068719227798283\n",
      "Validation Loss: 1.697234074526932e-05\n",
      "train time for 148 epochs, was 67.15916061401367\n",
      "\n",
      "EPOCH 150  (with max 500), loss: 0.0010643524583429098\n",
      "Validation Loss: 1.5849111150600947e-05\n",
      "train time for 150 epochs, was 67.54992818832397\n",
      "\n",
      "EPOCH 150 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0150.pth\n",
      "\n",
      "EPOCH 152  (with max 500), loss: 0.0008662253967486322\n",
      "Validation Loss: 1.532039459561929e-05\n",
      "train time for 152 epochs, was 69.23746371269226\n",
      "\n",
      "EPOCH 154  (with max 500), loss: 0.0007497384794987738\n",
      "Validation Loss: 1.5198914297798183e-05\n",
      "train time for 154 epochs, was 69.62736058235168\n",
      "\n",
      "EPOCH 155 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0155.pth\n",
      "\n",
      "EPOCH 156  (with max 500), loss: 0.0008810454746708274\n",
      "Validation Loss: 1.5218625776469707e-05\n",
      "train time for 156 epochs, was 71.39127969741821\n",
      "\n",
      "EPOCH 158  (with max 500), loss: 0.0009152013226412237\n",
      "Validation Loss: 1.506661283201538e-05\n",
      "train time for 158 epochs, was 71.78582763671875\n",
      "\n",
      "EPOCH 160  (with max 500), loss: 0.0008987130713649094\n",
      "Validation Loss: 1.4484192433883436e-05\n",
      "train time for 160 epochs, was 72.1854944229126\n",
      "\n",
      "EPOCH 160 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0160.pth\n",
      "\n",
      "EPOCH 162  (with max 500), loss: 0.0007221405976451933\n",
      "Validation Loss: 1.4125314010016154e-05\n",
      "train time for 162 epochs, was 74.0453953742981\n",
      "\n",
      "EPOCH 164  (with max 500), loss: 0.0005965612945146859\n",
      "Validation Loss: 1.3864605534763541e-05\n",
      "train time for 164 epochs, was 74.44254446029663\n",
      "\n",
      "EPOCH 165 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0165.pth\n",
      "\n",
      "EPOCH 166  (with max 500), loss: 0.0006887527415528893\n",
      "Validation Loss: 1.3487688192981295e-05\n",
      "train time for 166 epochs, was 76.18692564964294\n",
      "\n",
      "EPOCH 168  (with max 500), loss: 0.0008316673338413239\n",
      "Validation Loss: 1.3227308954810724e-05\n",
      "train time for 168 epochs, was 76.58547830581665\n",
      "\n",
      "EPOCH 170  (with max 500), loss: 0.0007647693855687976\n",
      "Validation Loss: 1.2977976439287886e-05\n",
      "train time for 170 epochs, was 76.98193550109863\n",
      "\n",
      "EPOCH 170 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0170.pth\n",
      "\n",
      "EPOCH 172  (with max 500), loss: 0.0006849264027550817\n",
      "Validation Loss: 1.2751292160828598e-05\n",
      "train time for 172 epochs, was 78.70195436477661\n",
      "\n",
      "EPOCH 174  (with max 500), loss: 0.0006084108026698232\n",
      "Validation Loss: 1.2542161130113527e-05\n",
      "train time for 174 epochs, was 79.10256052017212\n",
      "\n",
      "EPOCH 175 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0175.pth\n",
      "\n",
      "EPOCH 176  (with max 500), loss: 0.000615639379248023\n",
      "Validation Loss: 1.2161655831732787e-05\n",
      "train time for 176 epochs, was 80.84544539451599\n",
      "\n",
      "EPOCH 178  (with max 500), loss: 0.0006917768041603267\n",
      "Validation Loss: 1.2082310604455415e-05\n",
      "train time for 178 epochs, was 81.24835968017578\n",
      "\n",
      "EPOCH 180  (with max 500), loss: 0.0007542955572716892\n",
      "Validation Loss: 1.2038499335176311e-05\n",
      "train time for 180 epochs, was 81.6543641090393\n",
      "\n",
      "EPOCH 180 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0180.pth\n",
      "\n",
      "EPOCH 182  (with max 500), loss: 0.000963518803473562\n",
      "Validation Loss: 1.2032945960527286e-05\n",
      "train time for 182 epochs, was 83.56306958198547\n",
      "\n",
      "EPOCH 184  (with max 500), loss: 0.0007357122376561165\n",
      "Validation Loss: 1.1555885976122227e-05\n",
      "train time for 184 epochs, was 83.96812725067139\n",
      "\n",
      "EPOCH 185 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0185.pth\n",
      "\n",
      "EPOCH 186  (with max 500), loss: 0.0005993076483719051\n",
      "Validation Loss: 1.2047503332723863e-05\n",
      "train time for 186 epochs, was 85.7793242931366\n",
      "\n",
      "EPOCH 188  (with max 500), loss: 0.001042647985741496\n",
      "Validation Loss: 1.2859674825449474e-05\n",
      "train time for 188 epochs, was 86.18811225891113\n",
      "\n",
      "EPOCH 190  (with max 500), loss: 0.0006055348785594106\n",
      "Validation Loss: 1.4998029655544087e-05\n",
      "train time for 190 epochs, was 86.59461212158203\n",
      "\n",
      "EPOCH 190 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0190.pth\n",
      "\n",
      "EPOCH 192  (with max 500), loss: 0.001693060272373259\n",
      "Validation Loss: 1.1912553418369498e-05\n",
      "train time for 192 epochs, was 88.34424686431885\n",
      "\n",
      "EPOCH 194  (with max 500), loss: 0.0006003006128594279\n",
      "Validation Loss: 1.1993402949883603e-05\n",
      "train time for 194 epochs, was 88.74822330474854\n",
      "\n",
      "EPOCH 195 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0195.pth\n",
      "\n",
      "EPOCH 196  (with max 500), loss: 0.0007171894540078938\n",
      "Validation Loss: 1.0929756172117777e-05\n",
      "train time for 196 epochs, was 90.6468722820282\n",
      "\n",
      "EPOCH 198  (with max 500), loss: 0.0005356502952054143\n",
      "Validation Loss: 1.0956544429063797e-05\n",
      "train time for 198 epochs, was 91.06217408180237\n",
      "\n",
      "EPOCH 200  (with max 500), loss: 0.0005870506865903735\n",
      "Validation Loss: 1.1462650945759378e-05\n",
      "train time for 200 epochs, was 91.47251009941101\n",
      "\n",
      "EPOCH 200 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0200.pth\n",
      "\n",
      "EPOCH 202  (with max 500), loss: 0.0005035872454755008\n",
      "Validation Loss: 1.2490318113123067e-05\n",
      "train time for 202 epochs, was 93.25224256515503\n",
      "\n",
      "EPOCH 204  (with max 500), loss: 0.0007655239896848798\n",
      "Validation Loss: 1.3488477634382434e-05\n",
      "train time for 204 epochs, was 93.66341662406921\n",
      "\n",
      "EPOCH 205 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0205.pth\n",
      "\n",
      "EPOCH 206  (with max 500), loss: 0.0006543269846588373\n",
      "Validation Loss: 1.1274637472524773e-05\n",
      "train time for 206 epochs, was 95.5305871963501\n",
      "\n",
      "EPOCH 208  (with max 500), loss: 0.0005901885451748967\n",
      "Validation Loss: 1.0548235877649859e-05\n",
      "train time for 208 epochs, was 95.93942975997925\n",
      "\n",
      "EPOCH 210  (with max 500), loss: 0.0007108059944584966\n",
      "Validation Loss: 1.0109425602422561e-05\n",
      "train time for 210 epochs, was 96.35554623603821\n",
      "\n",
      "EPOCH 210 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0210.pth\n",
      "\n",
      "EPOCH 212  (with max 500), loss: 0.0006023260648362339\n",
      "Validation Loss: 9.541261533740908e-06\n",
      "train time for 212 epochs, was 98.24590349197388\n",
      "\n",
      "EPOCH 214  (with max 500), loss: 0.0005094486987218261\n",
      "Validation Loss: 9.117131412494928e-06\n",
      "train time for 214 epochs, was 98.63832831382751\n",
      "\n",
      "EPOCH 215 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0215.pth\n",
      "\n",
      "EPOCH 216  (with max 500), loss: 0.0006968422676436603\n",
      "Validation Loss: 8.85131612449186e-06\n",
      "train time for 216 epochs, was 100.31122851371765\n",
      "\n",
      "EPOCH 218  (with max 500), loss: 0.0005174180842004716\n",
      "Validation Loss: 8.727134627406485e-06\n",
      "train time for 218 epochs, was 100.70775032043457\n",
      "\n",
      "EPOCH 220  (with max 500), loss: 0.000488518737256527\n",
      "Validation Loss: 8.73718636285048e-06\n",
      "train time for 220 epochs, was 101.09951639175415\n",
      "\n",
      "EPOCH 220 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0220.pth\n",
      "\n",
      "EPOCH 222  (with max 500), loss: 0.0006222385563887656\n",
      "Validation Loss: 8.809240171103738e-06\n",
      "train time for 222 epochs, was 102.81090426445007\n",
      "\n",
      "EPOCH 224  (with max 500), loss: 0.0006024278118275106\n",
      "Validation Loss: 9.019111530506052e-06\n",
      "train time for 224 epochs, was 103.21006608009338\n",
      "\n",
      "EPOCH 225 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0225.pth\n",
      "\n",
      "EPOCH 226  (with max 500), loss: 0.0006139208562672138\n",
      "Validation Loss: 9.595324627298396e-06\n",
      "train time for 226 epochs, was 104.95214557647705\n",
      "\n",
      "EPOCH 228  (with max 500), loss: 0.0007417974411509931\n",
      "Validation Loss: 8.340720341948327e-06\n",
      "train time for 228 epochs, was 105.35917735099792\n",
      "\n",
      "EPOCH 230  (with max 500), loss: 0.00050098926294595\n",
      "Validation Loss: 8.224517841881607e-06\n",
      "train time for 230 epochs, was 105.77161693572998\n",
      "\n",
      "EPOCH 230 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0230.pth\n",
      "\n",
      "EPOCH 232  (with max 500), loss: 0.0004964187974110246\n",
      "Validation Loss: 8.092658390523866e-06\n",
      "train time for 232 epochs, was 107.59612727165222\n",
      "\n",
      "EPOCH 234  (with max 500), loss: 0.0006407054024748504\n",
      "Validation Loss: 8.022263500606641e-06\n",
      "train time for 234 epochs, was 108.00188708305359\n",
      "\n",
      "EPOCH 235 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0235.pth\n",
      "\n",
      "EPOCH 236  (with max 500), loss: 0.0005979155539534986\n",
      "Validation Loss: 8.058864295890089e-06\n",
      "train time for 236 epochs, was 109.72860860824585\n",
      "\n",
      "EPOCH 238  (with max 500), loss: 0.0005155677208676934\n",
      "Validation Loss: 8.225399142247625e-06\n",
      "train time for 238 epochs, was 110.13184809684753\n",
      "\n",
      "EPOCH 240  (with max 500), loss: 0.0006329719326458871\n",
      "Validation Loss: 8.481400982418563e-06\n",
      "train time for 240 epochs, was 110.52845573425293\n",
      "\n",
      "EPOCH 240 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0240.pth\n",
      "\n",
      "EPOCH 242  (with max 500), loss: 0.00043835933320224285\n",
      "Validation Loss: 8.70848452905193e-06\n",
      "train time for 242 epochs, was 112.33681011199951\n",
      "\n",
      "EPOCH 244  (with max 500), loss: 0.0004488325212150812\n",
      "Validation Loss: 7.756719242024701e-06\n",
      "train time for 244 epochs, was 112.7504472732544\n",
      "\n",
      "EPOCH 245 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0245.pth\n",
      "\n",
      "EPOCH 246  (with max 500), loss: 0.0004510172875598073\n",
      "Validation Loss: 7.724011084064841e-06\n",
      "train time for 246 epochs, was 114.61797547340393\n",
      "\n",
      "EPOCH 248  (with max 500), loss: 0.0006709378794766963\n",
      "Validation Loss: 7.32023590899189e-06\n",
      "train time for 248 epochs, was 115.05527400970459\n",
      "\n",
      "EPOCH 250  (with max 500), loss: 0.0005873412010259926\n",
      "Validation Loss: 7.187705250544241e-06\n",
      "train time for 250 epochs, was 115.46291947364807\n",
      "\n",
      "EPOCH 250 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0250.pth\n",
      "\n",
      "EPOCH 252  (with max 500), loss: 0.0005090270424261689\n",
      "Validation Loss: 7.505194844270591e-06\n",
      "train time for 252 epochs, was 117.3143196105957\n",
      "\n",
      "EPOCH 254  (with max 500), loss: 0.0005039215320721269\n",
      "Validation Loss: 7.541932973254006e-06\n",
      "train time for 254 epochs, was 117.71808695793152\n",
      "\n",
      "EPOCH 255 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0255.pth\n",
      "\n",
      "EPOCH 256  (with max 500), loss: 0.0004442042263690382\n",
      "Validation Loss: 7.3112823884002864e-06\n",
      "train time for 256 epochs, was 119.64214134216309\n",
      "\n",
      "EPOCH 258  (with max 500), loss: 0.00045442202826961875\n",
      "Validation Loss: 7.1859399213280994e-06\n",
      "train time for 258 epochs, was 120.04450249671936\n",
      "\n",
      "EPOCH 260  (with max 500), loss: 0.0005211372044868767\n",
      "Validation Loss: 6.999860033829464e-06\n",
      "train time for 260 epochs, was 120.45043706893921\n",
      "\n",
      "EPOCH 260 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0260.pth\n",
      "\n",
      "EPOCH 262  (with max 500), loss: 0.00039655211730860174\n",
      "Validation Loss: 6.856677828182001e-06\n",
      "train time for 262 epochs, was 123.1628828048706\n",
      "\n",
      "EPOCH 264  (with max 500), loss: 0.00042109371861442924\n",
      "Validation Loss: 6.68347684040782e-06\n",
      "train time for 264 epochs, was 123.5702772140503\n",
      "\n",
      "EPOCH 265 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0265.pth\n",
      "\n",
      "EPOCH 266  (with max 500), loss: 0.000412450113799423\n",
      "Validation Loss: 6.51572372589726e-06\n",
      "train time for 266 epochs, was 125.60573077201843\n",
      "\n",
      "EPOCH 268  (with max 500), loss: 0.00037328441976569593\n",
      "Validation Loss: 6.332963494060095e-06\n",
      "train time for 268 epochs, was 126.02540636062622\n",
      "\n",
      "EPOCH 270  (with max 500), loss: 0.0005204278277233243\n",
      "Validation Loss: 6.1242899391800165e-06\n",
      "train time for 270 epochs, was 126.44455695152283\n",
      "\n",
      "EPOCH 270 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0270.pth\n",
      "\n",
      "EPOCH 272  (with max 500), loss: 0.0003592276480048895\n",
      "Validation Loss: 5.965765012660995e-06\n",
      "train time for 272 epochs, was 129.00423908233643\n",
      "\n",
      "EPOCH 274  (with max 500), loss: 0.00035966202267445624\n",
      "Validation Loss: 5.849615263286978e-06\n",
      "train time for 274 epochs, was 129.47433805465698\n",
      "\n",
      "EPOCH 275 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0275.pth\n",
      "\n",
      "EPOCH 276  (with max 500), loss: 0.00040763127617537975\n",
      "Validation Loss: 5.748845524067292e-06\n",
      "train time for 276 epochs, was 132.66525077819824\n",
      "\n",
      "EPOCH 278  (with max 500), loss: 0.0004200673720333725\n",
      "Validation Loss: 5.665373009833274e-06\n",
      "train time for 278 epochs, was 133.06026816368103\n",
      "\n",
      "EPOCH 280  (with max 500), loss: 0.00037640900700353086\n",
      "Validation Loss: 5.597433755610837e-06\n",
      "train time for 280 epochs, was 133.45745635032654\n",
      "\n",
      "EPOCH 280 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0280.pth\n",
      "\n",
      "EPOCH 282  (with max 500), loss: 0.00034142250660806894\n",
      "Validation Loss: 5.516944838745985e-06\n",
      "train time for 282 epochs, was 135.2729012966156\n",
      "\n",
      "EPOCH 284  (with max 500), loss: 0.00030255207093432546\n",
      "Validation Loss: 5.418221462605288e-06\n",
      "train time for 284 epochs, was 135.6784896850586\n",
      "\n",
      "EPOCH 285 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0285.pth\n",
      "\n",
      "EPOCH 286  (with max 500), loss: 0.0003903424949385226\n",
      "Validation Loss: 5.356366727937711e-06\n",
      "train time for 286 epochs, was 137.4561471939087\n",
      "\n",
      "EPOCH 288  (with max 500), loss: 0.00030444495496340096\n",
      "Validation Loss: 5.2709769988723565e-06\n",
      "train time for 288 epochs, was 137.85491585731506\n",
      "\n",
      "EPOCH 290  (with max 500), loss: 0.00026446886477060616\n",
      "Validation Loss: 5.186849648453062e-06\n",
      "train time for 290 epochs, was 138.26430487632751\n",
      "\n",
      "EPOCH 290 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0290.pth\n",
      "\n",
      "EPOCH 292  (with max 500), loss: 0.0005265097715891898\n",
      "Validation Loss: 5.072844487585826e-06\n",
      "train time for 292 epochs, was 140.1161506175995\n",
      "\n",
      "EPOCH 294  (with max 500), loss: 0.0003829300112556666\n",
      "Validation Loss: 4.979499863111414e-06\n",
      "train time for 294 epochs, was 140.52691340446472\n",
      "\n",
      "EPOCH 295 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0295.pth\n",
      "\n",
      "EPOCH 296  (with max 500), loss: 0.00031908205710351467\n",
      "Validation Loss: 5.286030500428751e-06\n",
      "train time for 296 epochs, was 142.36533784866333\n",
      "\n",
      "EPOCH 298  (with max 500), loss: 0.000311184034217149\n",
      "Validation Loss: 5.869632332178298e-06\n",
      "train time for 298 epochs, was 142.78400564193726\n",
      "\n",
      "EPOCH 300  (with max 500), loss: 0.0003343261778354645\n",
      "Validation Loss: 4.856525265495293e-06\n",
      "train time for 300 epochs, was 143.19129085540771\n",
      "\n",
      "EPOCH 300 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0300.pth\n",
      "\n",
      "EPOCH 302  (with max 500), loss: 0.0004276736290194094\n",
      "Validation Loss: 4.628775513992878e-06\n",
      "train time for 302 epochs, was 145.10672330856323\n",
      "\n",
      "EPOCH 304  (with max 500), loss: 0.0002554264501668513\n",
      "Validation Loss: 4.562102731142659e-06\n",
      "train time for 304 epochs, was 145.50572800636292\n",
      "\n",
      "EPOCH 305 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0305.pth\n",
      "\n",
      "EPOCH 306  (with max 500), loss: 0.0004379382007755339\n",
      "Validation Loss: 4.553517101157922e-06\n",
      "train time for 306 epochs, was 148.03467726707458\n",
      "\n",
      "EPOCH 308  (with max 500), loss: 0.0002408508735243231\n",
      "Validation Loss: 4.608850304066436e-06\n",
      "train time for 308 epochs, was 148.44449305534363\n",
      "\n",
      "EPOCH 310  (with max 500), loss: 0.0002648246299941093\n",
      "Validation Loss: 4.708365395345027e-06\n",
      "train time for 310 epochs, was 148.85150265693665\n",
      "\n",
      "EPOCH 310 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0310.pth\n",
      "\n",
      "EPOCH 312  (with max 500), loss: 0.00045083725126460195\n",
      "Validation Loss: 4.819487003260292e-06\n",
      "train time for 312 epochs, was 150.61399579048157\n",
      "\n",
      "EPOCH 314  (with max 500), loss: 0.0003051174571737647\n",
      "Validation Loss: 4.8401529966213275e-06\n",
      "train time for 314 epochs, was 151.0327353477478\n",
      "\n",
      "EPOCH 315 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0315.pth\n",
      "\n",
      "EPOCH 316  (with max 500), loss: 0.00032707673381082714\n",
      "Validation Loss: 4.803784122486832e-06\n",
      "train time for 316 epochs, was 152.94419074058533\n",
      "\n",
      "EPOCH 318  (with max 500), loss: 0.00039794668555259705\n",
      "Validation Loss: 4.708991127699846e-06\n",
      "train time for 318 epochs, was 153.35284304618835\n",
      "\n",
      "EPOCH 320  (with max 500), loss: 0.00035929190926253796\n",
      "Validation Loss: 4.578439074975904e-06\n",
      "train time for 320 epochs, was 153.78123879432678\n",
      "\n",
      "EPOCH 320 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0320.pth\n",
      "\n",
      "EPOCH 322  (with max 500), loss: 0.0006013564998283982\n",
      "Validation Loss: 4.4532189349411055e-06\n",
      "train time for 322 epochs, was 155.5903263092041\n",
      "\n",
      "EPOCH 324  (with max 500), loss: 0.00034491627593524754\n",
      "Validation Loss: 4.576347237161826e-06\n",
      "train time for 324 epochs, was 155.99878525733948\n",
      "\n",
      "EPOCH 325 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0325.pth\n",
      "\n",
      "EPOCH 326  (with max 500), loss: 0.0002710446424316615\n",
      "Validation Loss: 6.047470833436819e-06\n",
      "train time for 326 epochs, was 157.81805539131165\n",
      "\n",
      "EPOCH 328  (with max 500), loss: 0.00028081986238248646\n",
      "Validation Loss: 9.299756129621528e-06\n",
      "train time for 328 epochs, was 158.2302107810974\n",
      "\n",
      "EPOCH 330  (with max 500), loss: 0.00039888909668661654\n",
      "Validation Loss: 1.06551642602426e-05\n",
      "train time for 330 epochs, was 158.63767433166504\n",
      "\n",
      "EPOCH 330 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0330.pth\n",
      "\n",
      "EPOCH 332  (with max 500), loss: 0.0003596935421228409\n",
      "Validation Loss: 5.881762717763195e-06\n",
      "train time for 332 epochs, was 160.4620532989502\n",
      "\n",
      "EPOCH 334  (with max 500), loss: 0.00040043360786512494\n",
      "Validation Loss: 4.694303697760915e-06\n",
      "train time for 334 epochs, was 160.881192445755\n",
      "\n",
      "EPOCH 335 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0335.pth\n",
      "\n",
      "EPOCH 336  (with max 500), loss: 0.0002861711836885661\n",
      "Validation Loss: 4.537097993306816e-06\n",
      "train time for 336 epochs, was 163.00079369544983\n",
      "\n",
      "EPOCH 338  (with max 500), loss: 0.00031484320061281323\n",
      "Validation Loss: 4.4931198317499366e-06\n",
      "train time for 338 epochs, was 163.4016604423523\n",
      "\n",
      "EPOCH 340  (with max 500), loss: 0.00028375524561852217\n",
      "Validation Loss: 4.453047949937172e-06\n",
      "train time for 340 epochs, was 163.79512977600098\n",
      "\n",
      "EPOCH 340 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0340.pth\n",
      "\n",
      "EPOCH 342  (with max 500), loss: 0.00031312869396060705\n",
      "Validation Loss: 4.349528808234027e-06\n",
      "train time for 342 epochs, was 165.9915587902069\n",
      "\n",
      "EPOCH 344  (with max 500), loss: 0.0002912813797593117\n",
      "Validation Loss: 4.264769813744351e-06\n",
      "train time for 344 epochs, was 166.3961374759674\n",
      "\n",
      "EPOCH 345 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0345.pth\n",
      "\n",
      "EPOCH 346  (with max 500), loss: 0.0003419070562813431\n",
      "Validation Loss: 4.167012320976937e-06\n",
      "train time for 346 epochs, was 168.23312902450562\n",
      "\n",
      "EPOCH 348  (with max 500), loss: 0.0002933529613073915\n",
      "Validation Loss: 4.08248342864681e-06\n",
      "train time for 348 epochs, was 168.65231132507324\n",
      "\n",
      "EPOCH 350  (with max 500), loss: 0.0002962224534712732\n",
      "Validation Loss: 4.0291197365149856e-06\n",
      "train time for 350 epochs, was 169.06496334075928\n",
      "\n",
      "EPOCH 350 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0350.pth\n",
      "\n",
      "EPOCH 352  (with max 500), loss: 0.0003517860022839159\n",
      "Validation Loss: 4.151476787228603e-06\n",
      "train time for 352 epochs, was 170.97904253005981\n",
      "\n",
      "EPOCH 354  (with max 500), loss: 0.0002849272859748453\n",
      "Validation Loss: 4.537618679023581e-06\n",
      "train time for 354 epochs, was 171.38957738876343\n",
      "\n",
      "EPOCH 355 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0355.pth\n",
      "\n",
      "EPOCH 356  (with max 500), loss: 0.0002506072341930121\n",
      "Validation Loss: 5.2204018174961675e-06\n",
      "train time for 356 epochs, was 173.21858072280884\n",
      "\n",
      "EPOCH 358  (with max 500), loss: 0.0003044217883143574\n",
      "Validation Loss: 4.657566023524851e-06\n",
      "train time for 358 epochs, was 173.62794041633606\n",
      "\n",
      "EPOCH 360  (with max 500), loss: 0.00031706425943411887\n",
      "Validation Loss: 4.464929133973783e-06\n",
      "train time for 360 epochs, was 174.03803300857544\n",
      "\n",
      "EPOCH 360 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0360.pth\n",
      "\n",
      "EPOCH 362  (with max 500), loss: 0.0002811288577504456\n",
      "Validation Loss: 4.355182227300247e-06\n",
      "train time for 362 epochs, was 175.9267761707306\n",
      "\n",
      "EPOCH 364  (with max 500), loss: 0.00039771824958734214\n",
      "Validation Loss: 4.467945927899564e-06\n",
      "train time for 364 epochs, was 176.33132362365723\n",
      "\n",
      "EPOCH 365 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0365.pth\n",
      "\n",
      "EPOCH 366  (with max 500), loss: 0.0003333287895657122\n",
      "Validation Loss: 4.6500085773004685e-06\n",
      "train time for 366 epochs, was 178.22337174415588\n",
      "\n",
      "EPOCH 368  (with max 500), loss: 0.00026460736989974976\n",
      "Validation Loss: 4.76239029012504e-06\n",
      "train time for 368 epochs, was 178.62938117980957\n",
      "\n",
      "EPOCH 370  (with max 500), loss: 0.0002849535667337477\n",
      "Validation Loss: 4.76987452202593e-06\n",
      "train time for 370 epochs, was 179.03966903686523\n",
      "\n",
      "EPOCH 370 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0370.pth\n",
      "\n",
      "EPOCH 372  (with max 500), loss: 0.00024456027313135564\n",
      "Validation Loss: 4.512083251029253e-06\n",
      "train time for 372 epochs, was 180.90206241607666\n",
      "\n",
      "EPOCH 374  (with max 500), loss: 0.0003417441330384463\n",
      "Validation Loss: 3.828041371889412e-06\n",
      "train time for 374 epochs, was 181.31054425239563\n",
      "\n",
      "EPOCH 375 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0375.pth\n",
      "\n",
      "EPOCH 376  (with max 500), loss: 0.00026743326452560723\n",
      "Validation Loss: 3.6826747873419663e-06\n",
      "train time for 376 epochs, was 183.20320868492126\n",
      "\n",
      "EPOCH 378  (with max 500), loss: 0.00022805763001088053\n",
      "Validation Loss: 3.6072613056603586e-06\n",
      "train time for 378 epochs, was 183.61078429222107\n",
      "\n",
      "EPOCH 380  (with max 500), loss: 0.00021762229152955115\n",
      "Validation Loss: 3.5749314974964364e-06\n",
      "train time for 380 epochs, was 184.01958513259888\n",
      "\n",
      "EPOCH 380 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0380.pth\n",
      "\n",
      "EPOCH 382  (with max 500), loss: 0.00023992023488972336\n",
      "Validation Loss: 3.5600712635641685e-06\n",
      "train time for 382 epochs, was 185.93595933914185\n",
      "\n",
      "EPOCH 384  (with max 500), loss: 0.00021559167362283915\n",
      "Validation Loss: 3.6360293051984627e-06\n",
      "train time for 384 epochs, was 186.3479232788086\n",
      "\n",
      "EPOCH 385 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0385.pth\n",
      "\n",
      "EPOCH 386  (with max 500), loss: 0.00026990362675860524\n",
      "Validation Loss: 3.934027063223766e-06\n",
      "train time for 386 epochs, was 188.1590027809143\n",
      "\n",
      "EPOCH 388  (with max 500), loss: 0.00023312419943977147\n",
      "Validation Loss: 4.34478533861693e-06\n",
      "train time for 388 epochs, was 188.58124160766602\n",
      "\n",
      "EPOCH 390  (with max 500), loss: 0.00036967432242818177\n",
      "Validation Loss: 4.207059191685403e-06\n",
      "train time for 390 epochs, was 188.99419617652893\n",
      "\n",
      "EPOCH 390 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0390.pth\n",
      "\n",
      "EPOCH 392  (with max 500), loss: 0.0002939723781310022\n",
      "Validation Loss: 3.7975057693984127e-06\n",
      "train time for 392 epochs, was 190.8336262702942\n",
      "\n",
      "EPOCH 394  (with max 500), loss: 0.00027593711274676025\n",
      "Validation Loss: 3.5321959330758546e-06\n",
      "train time for 394 epochs, was 191.25810170173645\n",
      "\n",
      "EPOCH 395 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0395.pth\n",
      "\n",
      "EPOCH 396  (with max 500), loss: 0.0002652664261404425\n",
      "Validation Loss: 3.5087180094706127e-06\n",
      "train time for 396 epochs, was 193.1624720096588\n",
      "\n",
      "EPOCH 398  (with max 500), loss: 0.00019881084153894335\n",
      "Validation Loss: 3.5964237667940324e-06\n",
      "train time for 398 epochs, was 193.56746983528137\n",
      "\n",
      "EPOCH 400  (with max 500), loss: 0.0001949635916389525\n",
      "Validation Loss: 3.7199051803327166e-06\n",
      "train time for 400 epochs, was 193.9767427444458\n",
      "\n",
      "EPOCH 400 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0400.pth\n",
      "\n",
      "EPOCH 402  (with max 500), loss: 0.000300863990560174\n",
      "Validation Loss: 3.678842176668695e-06\n",
      "train time for 402 epochs, was 195.94892477989197\n",
      "\n",
      "EPOCH 404  (with max 500), loss: 0.0002989957283716649\n",
      "Validation Loss: 3.35344998347864e-06\n",
      "train time for 404 epochs, was 196.34746098518372\n",
      "\n",
      "EPOCH 405 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0405.pth\n",
      "\n",
      "EPOCH 406  (with max 500), loss: 0.00018331849423702806\n",
      "Validation Loss: 3.2409873256256105e-06\n",
      "train time for 406 epochs, was 198.2066671848297\n",
      "\n",
      "EPOCH 408  (with max 500), loss: 0.00022846130013931543\n",
      "Validation Loss: 3.341645879118005e-06\n",
      "train time for 408 epochs, was 198.6049473285675\n",
      "\n",
      "EPOCH 410  (with max 500), loss: 0.0004510932485572994\n",
      "Validation Loss: 3.5776063214143505e-06\n",
      "train time for 410 epochs, was 199.00868153572083\n",
      "\n",
      "EPOCH 410 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0410.pth\n",
      "\n",
      "EPOCH 412  (with max 500), loss: 0.0002717932511586696\n",
      "Validation Loss: 3.7739641811640467e-06\n",
      "train time for 412 epochs, was 200.90690350532532\n",
      "\n",
      "EPOCH 414  (with max 500), loss: 0.00021547838696278632\n",
      "Validation Loss: 3.8918419704714324e-06\n",
      "train time for 414 epochs, was 201.31778383255005\n",
      "\n",
      "EPOCH 415 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0415.pth\n",
      "\n",
      "EPOCH 416  (with max 500), loss: 0.0002393183094682172\n",
      "Validation Loss: 3.865143753500888e-06\n",
      "train time for 416 epochs, was 203.18060874938965\n",
      "\n",
      "EPOCH 418  (with max 500), loss: 0.00043198553612455726\n",
      "Validation Loss: 3.7306517697288655e-06\n",
      "train time for 418 epochs, was 203.59698677062988\n",
      "\n",
      "EPOCH 420  (with max 500), loss: 0.0002647734945639968\n",
      "Validation Loss: 4.585043370752828e-06\n",
      "train time for 420 epochs, was 203.9998836517334\n",
      "\n",
      "EPOCH 420 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0420.pth\n",
      "\n",
      "EPOCH 422  (with max 500), loss: 0.00021820934489369392\n",
      "Validation Loss: 5.0433268370397855e-06\n",
      "train time for 422 epochs, was 206.24142146110535\n",
      "\n",
      "EPOCH 424  (with max 500), loss: 0.00025076698511838913\n",
      "Validation Loss: 4.659556452679681e-06\n",
      "train time for 424 epochs, was 206.6507797241211\n",
      "\n",
      "EPOCH 425 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0425.pth\n",
      "\n",
      "EPOCH 426  (with max 500), loss: 0.00024172906705643982\n",
      "Validation Loss: 4.5659608076675795e-06\n",
      "train time for 426 epochs, was 208.5993926525116\n",
      "\n",
      "EPOCH 428  (with max 500), loss: 0.00035663534072227776\n",
      "Validation Loss: 3.5727250633499352e-06\n",
      "train time for 428 epochs, was 209.02151107788086\n",
      "\n",
      "EPOCH 430  (with max 500), loss: 0.00023254024563357234\n",
      "Validation Loss: 4.060495939484099e-06\n",
      "train time for 430 epochs, was 209.43630647659302\n",
      "\n",
      "EPOCH 430 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0430.pth\n",
      "\n",
      "EPOCH 432  (with max 500), loss: 0.0003244364052079618\n",
      "Validation Loss: 3.303475295979297e-06\n",
      "train time for 432 epochs, was 211.56388545036316\n",
      "\n",
      "EPOCH 434  (with max 500), loss: 0.00029837715555913746\n",
      "Validation Loss: 3.6423450637812493e-06\n",
      "train time for 434 epochs, was 211.97830200195312\n",
      "\n",
      "EPOCH 435 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0435.pth\n",
      "\n",
      "EPOCH 436  (with max 500), loss: 0.0002596309350337833\n",
      "Validation Loss: 4.223140422254801e-06\n",
      "train time for 436 epochs, was 213.9001088142395\n",
      "\n",
      "EPOCH 438  (with max 500), loss: 0.00031297976966015995\n",
      "Validation Loss: 4.565849394566612e-06\n",
      "train time for 438 epochs, was 214.30913853645325\n",
      "\n",
      "EPOCH 440  (with max 500), loss: 0.00031811074586585164\n",
      "Validation Loss: 4.38890265286318e-06\n",
      "train time for 440 epochs, was 214.71392560005188\n",
      "\n",
      "EPOCH 440 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0440.pth\n",
      "\n",
      "EPOCH 442  (with max 500), loss: 0.0003869163047056645\n",
      "Validation Loss: 4.007857114629587e-06\n",
      "train time for 442 epochs, was 216.67560625076294\n",
      "\n",
      "EPOCH 444  (with max 500), loss: 0.00022524934320244938\n",
      "Validation Loss: 3.9579135773237795e-06\n",
      "train time for 444 epochs, was 217.08623361587524\n",
      "\n",
      "EPOCH 445 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0445.pth\n",
      "\n",
      "EPOCH 446  (with max 500), loss: 0.0002752311993390322\n",
      "Validation Loss: 4.21307004216942e-06\n",
      "train time for 446 epochs, was 219.00532031059265\n",
      "\n",
      "EPOCH 448  (with max 500), loss: 0.00024915573885664344\n",
      "Validation Loss: 4.284133865439799e-06\n",
      "train time for 448 epochs, was 219.4147596359253\n",
      "\n",
      "EPOCH 450  (with max 500), loss: 0.0002601296582724899\n",
      "Validation Loss: 6.101847702666419e-06\n",
      "train time for 450 epochs, was 219.82322216033936\n",
      "\n",
      "EPOCH 450 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0450.pth\n",
      "\n",
      "EPOCH 452  (with max 500), loss: 0.000212568644201383\n",
      "Validation Loss: 4.176582478976343e-06\n",
      "train time for 452 epochs, was 221.73704433441162\n",
      "\n",
      "EPOCH 454  (with max 500), loss: 0.0002778976922854781\n",
      "Validation Loss: 5.142906047694851e-06\n",
      "train time for 454 epochs, was 222.15365982055664\n",
      "\n",
      "EPOCH 455 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0455.pth\n",
      "\n",
      "EPOCH 456  (with max 500), loss: 0.0002155077672796324\n",
      "Validation Loss: 7.254804586409591e-06\n",
      "train time for 456 epochs, was 224.04603576660156\n",
      "\n",
      "EPOCH 458  (with max 500), loss: 0.000546687631867826\n",
      "Validation Loss: 5.980509286018787e-06\n",
      "train time for 458 epochs, was 224.45874619483948\n",
      "\n",
      "EPOCH 460  (with max 500), loss: 0.000353778712451458\n",
      "Validation Loss: 2.0795565433218144e-05\n",
      "train time for 460 epochs, was 224.8813180923462\n",
      "\n",
      "EPOCH 460 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0460.pth\n",
      "\n",
      "EPOCH 462  (with max 500), loss: 0.0007328645442612469\n",
      "Validation Loss: 1.1090403859270737e-05\n",
      "train time for 462 epochs, was 226.82676577568054\n",
      "\n",
      "EPOCH 464  (with max 500), loss: 0.00036476703826338053\n",
      "Validation Loss: 1.3905568266636692e-05\n",
      "train time for 464 epochs, was 227.23403215408325\n",
      "\n",
      "EPOCH 465 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0465.pth\n",
      "\n",
      "EPOCH 466  (with max 500), loss: 0.0007135518244467676\n",
      "Validation Loss: 3.837213625956792e-06\n",
      "train time for 466 epochs, was 229.12137579917908\n",
      "\n",
      "EPOCH 468  (with max 500), loss: 0.0002919550461228937\n",
      "Validation Loss: 3.9325236684817355e-06\n",
      "train time for 468 epochs, was 229.52029967308044\n",
      "\n",
      "EPOCH 470  (with max 500), loss: 0.00022338368580676615\n",
      "Validation Loss: 6.657111043750774e-06\n",
      "train time for 470 epochs, was 229.92478919029236\n",
      "\n",
      "EPOCH 470 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0470.pth\n",
      "\n",
      "EPOCH 472  (with max 500), loss: 0.0005389645230025053\n",
      "Validation Loss: 7.682780051254667e-06\n",
      "train time for 472 epochs, was 231.89350295066833\n",
      "\n",
      "EPOCH 474  (with max 500), loss: 0.00026855364558286965\n",
      "Validation Loss: 8.661360880068969e-06\n",
      "train time for 474 epochs, was 232.30662369728088\n",
      "\n",
      "EPOCH 475 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0475.pth\n",
      "\n",
      "EPOCH 476  (with max 500), loss: 0.0002536411629989743\n",
      "Validation Loss: 8.963710570242256e-06\n",
      "train time for 476 epochs, was 234.23572516441345\n",
      "\n",
      "EPOCH 478  (with max 500), loss: 0.0002439480012981221\n",
      "Validation Loss: 6.969554760871688e-06\n",
      "train time for 478 epochs, was 234.65070819854736\n",
      "\n",
      "EPOCH 480  (with max 500), loss: 0.00027247806428931653\n",
      "Validation Loss: 4.667461780627491e-06\n",
      "train time for 480 epochs, was 235.06405878067017\n",
      "\n",
      "EPOCH 480 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0480.pth\n",
      "\n",
      "EPOCH 482  (with max 500), loss: 0.0003018421703018248\n",
      "Validation Loss: 4.0797995097818784e-06\n",
      "train time for 482 epochs, was 237.0204358100891\n",
      "\n",
      "EPOCH 484  (with max 500), loss: 0.00028139378991909325\n",
      "Validation Loss: 3.920902599929832e-06\n",
      "train time for 484 epochs, was 237.4324951171875\n",
      "\n",
      "EPOCH 485 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0485.pth\n",
      "\n",
      "EPOCH 486  (with max 500), loss: 0.0002765040844678879\n",
      "Validation Loss: 3.7621482533722883e-06\n",
      "train time for 486 epochs, was 239.3390336036682\n",
      "\n",
      "EPOCH 488  (with max 500), loss: 0.0002536820829845965\n",
      "Validation Loss: 3.4768145269481465e-06\n",
      "train time for 488 epochs, was 239.7522840499878\n",
      "\n",
      "EPOCH 490  (with max 500), loss: 0.000300758023513481\n",
      "Validation Loss: 5.187336682865862e-06\n",
      "train time for 490 epochs, was 240.1697154045105\n",
      "\n",
      "EPOCH 490 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0490.pth\n",
      "\n",
      "EPOCH 492  (with max 500), loss: 0.0008299677283503115\n",
      "Validation Loss: 3.153785883114324e-06\n",
      "train time for 492 epochs, was 242.1112904548645\n",
      "\n",
      "EPOCH 494  (with max 500), loss: 0.0001873369183158502\n",
      "Validation Loss: 3.1408019367518136e-06\n",
      "train time for 494 epochs, was 242.5267367362976\n",
      "\n",
      "EPOCH 495 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0495.pth\n",
      "\n",
      "EPOCH 496  (with max 500), loss: 0.0001966843119589612\n",
      "Validation Loss: 5.627742211800069e-06\n",
      "train time for 496 epochs, was 244.4793984889984\n",
      "\n",
      "EPOCH 498  (with max 500), loss: 0.00043427475611679256\n",
      "Validation Loss: 3.282034413132351e-06\n",
      "train time for 498 epochs, was 244.89075660705566\n",
      "\n",
      "EPOCH 500  (with max 500), loss: 0.00023439814685843885\n",
      "Validation Loss: 3.4815741400961997e-06\n",
      "train time for 500 epochs, was 245.30575466156006\n",
      "\n",
      "EPOCH 500 save model to : runs/mini_test_01/out.e512.l4.h8_chkpt_0500.pth\n",
      "\n",
      "train time for 500 epochs, was 246.91411328315735\n",
      "loss  =  0.00023439814685843885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(model, optimizer, dataloader, num_epochs, device, outdir, basefname, start_epoch=0, checkpoint_path=None):\n",
    "    t0 = time.time()\n",
    "    max_epoch = start_epoch + num_epochs\n",
    "    for epoch in range(start_epoch, max_epoch):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        for batch_idx, (input_data, target_data, cond_data) in enumerate(dataloader):\n",
    "            if verboselevel > 5 :\n",
    "                print(f' ---- submitting batch with input_data={input_data.shape}, target_data={target_data.shape}, cond_data={cond_data.shape}')\n",
    "            #print(f\"b{batch_idx} \", end='')\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Move inputs and targets to the device\n",
    "            input_data, target_data, cond_data = input_data.to(device), target_data.to(device), cond_data.to(device)\n",
    "            \n",
    "            if cond_size==0 :  #Ignore conditioning data\n",
    "                cond_expanded=None\n",
    "            else : \n",
    "                # for dataset exammples, expand the conditioning info across all time steps before passing to models\n",
    "                cond_expanded = cond_data.unsqueeze(1).expand(-1, input_data.size(1), -1)\n",
    "            \n",
    "            #print(f'    after loading a batch,  input_data.shape is {input_data.shape}, and cond_data.shape is {cond_data.shape}')\n",
    "            #print(f'    after loading a batch,  cond_expanded.shape is {cond_expanded.shape}')\n",
    "            #print(f'    after loading a batch,  mask.shape is {mask.shape}')\n",
    "            #print(f' model={model}')\n",
    "            \n",
    "            # torch.Size([batch_size, seq_len, num_tokens, vocab_size])\n",
    "            output = model(input_data, cond_expanded, mask)\n",
    "        \n",
    "            if verboselevel > 5 :\n",
    "                print(f' TTTTTTTT after training, output shape ={output.shape}, torch.Size([batch_size, seq_len, num_tokens, vocab_size])')\n",
    "                print(f' TTTTTTTT Passing to CRITERION with , output.reshape(-1, vocab_size) = {output.reshape(-1, vocab_size).shape} and target_data.reshape(-1) = {target_data.reshape(-1).shape}' )\n",
    "    \n",
    "            ##  this works, but is too verbose >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "            ##      # Original shape: (batch_size, seq_len, num_tokens, vocab_size)\n",
    "            ##      output = output.reshape(batch_size, sequence_length * num_tokens, vocab_size)\n",
    "            ##      # Original shape: (batch_size, seq_len, num_tokens)\n",
    "            ##      targets = targets.reshape(batch_size, sequence_length * num_tokens)\n",
    "            ##      loss = criterion(output.permute(0, 2, 1), targets) \n",
    "            \n",
    "            ##  more succinct <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            #   Computes the CE for each token separately, and then averages them to get the loss.\n",
    "            #loss = criterion(output.reshape(-1, vocab_size), target_data.reshape(-1)) # collapses all target_data dimensions into a single dimension\n",
    "            loss = criterion(output.reshape(-1, vocab_size), target_data.reshape(-1).long())\n",
    "            ## <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch+1) % ErrorLogRate == 0:\n",
    "            print(f'EPOCH {epoch+1}  (with max {max_epoch}), ', end='')\n",
    "            print(f'loss: {loss}')\n",
    "            # Log the loss to TensorBoard\n",
    "            writer.add_scalar('Loss/train', loss, epoch)\n",
    "            \n",
    "            if validator_data_dir != None :\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loss = 0\n",
    "                    for val_inputs, val_targets, cond_data in validator_dataloader:\n",
    "                        val_inputs, val_targets, cond_data = val_inputs.to(device), val_targets.to(device), cond_data.to(device)\n",
    "                        \n",
    "                        if cond_size==0 :  #Ignore conditioning data\n",
    "                            cond_expanded=None\n",
    "                        else: \n",
    "                            # for dataset exammples, expand the conditioning info across all time steps before passing to models\n",
    "                            cond_expanded = cond_data.unsqueeze(1).expand(-1, input_data.size(1), -1)\n",
    "    \n",
    "                        \n",
    "                        val_outputs = model(val_inputs,cond_expanded, mask)\n",
    "                        \n",
    "                        val_loss += criterion(val_outputs.reshape(-1, vocab_size), val_targets.reshape(-1).long()) # collapses all target_data dimensions into a single dimension\n",
    "                        #val_loss += criterion(val_outputs, val_targets).item()\n",
    "    \n",
    "                print(f'Validation Loss: {val_loss / len(validator_dataloader)}')\n",
    "                writer.add_scalar('Loss/validation', val_loss / len(validator_dataloader), epoch)\n",
    "    \n",
    "                t1 = time.time()\n",
    "                train_time = t1-t0\n",
    "                print(f'train time for {epoch-start_epoch+1} epochs, was {train_time}' )\n",
    "                print(f'')\n",
    "                \n",
    "        if (epoch+1) % checkpoint_interval == 0:\n",
    "            lastbasename = outdir+\"/\"+basefname+\"_chkpt_\"+str(epoch+1).zfill(4)\n",
    "            print(f'EPOCH {epoch+1} save model to : {lastbasename}.pth')\n",
    "            print(f'')\n",
    "            save_model(model, optimizer, Ti,  lastbasename +\".pth\")\n",
    "        \n",
    "    \n",
    "    t1 = time.time()\n",
    "    train_time = t1-t0\n",
    "    print(f'train time for {num_epochs} epochs, was {train_time}' )\n",
    "    print(f'loss  =  {loss}' )\n",
    "    \n",
    "## -----------------------------------------------------------------------------------\n",
    "## OK, let's do it!\n",
    "train(model, optimizer, dataloader, num_epochs, device, outdir, basefname, start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16eb43b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just check that inference attention mask will look right\n",
    "#Actually, the inference mask can be None since we are using a context window only as long as the maximum look-back in the training mask\n",
    "# thats why taking the mask with :TI is upper-triangular. Longer dims would show a banded mask again.\n",
    "foo=mask[:Ti, :Ti]\n",
    "foo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871a1f25-78a6-479b-8771-2910cf639d67",
   "metadata": {},
   "source": [
    "### <font color='blue'> Use Inference.Decode.ipynb to see and hear your generated audio   \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68274809-4986-4d54-a442-ba7ac8b48ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
